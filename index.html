<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        :root {
            --primary-color: #1a365d;
            --secondary-color: #2c5282;
            --accent-color: #3182ce;
            --light-bg: #f8f9fa;
            --dark-bg: #1a202c;
            --text-color: #2d3748;
            --light-text: #f8f9fa;
            --border-radius: 4px;
            --box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            --transition: all 0.3s ease;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Source Sans Pro', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--light-bg);
            overflow-x: hidden;
        }
        
        @import url('https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@300;400;600;700&family=Source+Serif+Pro:wght@400;600;700&display=swap');

        .container {
            width: 100%;
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background: var(--primary-color);
            color: var(--light-text);
            padding: 3rem 0;
            text-align: center;
            position: relative;
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
            position: relative;
            z-index: 2;
            padding: 0 20px;
        }

        h1 {
            font-family: 'Source Serif Pro', Georgia, serif;
            font-size: 2.8rem;
            margin-bottom: 1.5rem;
            line-height: 1.2;
            color: var(--light-text);
            font-weight: 700;
        }

        .subtitle {
            font-size: 1.2rem;
            margin-bottom: 2rem;
            color: rgba(255, 255, 255, 0.9);
            font-weight: 400;
        }

        .authors {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 2rem;
            margin-bottom: 2rem;
        }

        .author {
            position: relative;
        }

        .author a {
            color: var(--light-text);
            text-decoration: none;
            font-weight: 400;
            border-bottom: 1px dotted rgba(255, 255, 255, 0.5);
            transition: var(--transition);
        }

        .author a:hover {
            color: var(--accent-color);
            border-bottom-color: var(--accent-color);
        }

        .btn-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 1.5rem;
            margin: 2.5rem 0;
            perspective: 1000px;
        }

        .btn-primary {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            background-color: var(--accent-color);
            color: white;
            border: none;
            border-radius: var(--border-radius);
            text-decoration: none;
            font-weight: 600;
            transition: var(--transition);
            box-shadow: var(--box-shadow);
        }

        .btn-primary:hover {
            background-color: var(--secondary-color);
            transform: translateY(-2px);
        }

        .btn-primary i {
            font-size: 1.2rem;
        }

        .video-container {
            width: 100%;
            max-width: 800px;
            margin: 2rem auto;
            background-color: #000;
            border-radius: var(--border-radius);
            overflow: hidden;
            position: relative;
            padding-top: 56.25%; /* 16:9 Aspect Ratio */
            box-shadow: var(--box-shadow);
        }

        .video-placeholder {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
            font-size: 1.2rem;
            background: #1a202c;
        }
        
        .video-placeholder p {
            padding: 10px 20px;
        }

        .section {
            padding: 3rem 0;
            background-color: white;
            margin: 2rem 0;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            position: relative;
            overflow: hidden;
        }
        
        .section::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 3px;
            height: 100%;
            background: var(--accent-color);
        }

        .section-header {
            text-align: center;
            margin-bottom: 2rem;
        }

        .section-header h2 {
            font-family: 'Source Serif Pro', Georgia, serif;
            font-size: 2rem;
            color: var(--primary-color);
            position: relative;
            display: inline-block;
            padding-bottom: 0.5rem;
            font-weight: 600;
        }

        .section-header h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 60px;
            height: 2px;
            background: var(--accent-color);
        }

        .section-content {
            padding: 0 2rem;
            position: relative;
            z-index: 1;
        }

        .abstract {
            background-color: white;
            padding: 2rem;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            margin: 2rem 0;
            position: relative;
            overflow: hidden;
            border-left: 3px solid var(--primary-color);
        }

        .abstract h2 {
            font-family: 'Source Serif Pro', Georgia, serif;
            color: var(--primary-color);
            margin-bottom: 1.5rem;
            font-size: 1.8rem;
            position: relative;
            display: inline-block;
            padding-bottom: 0.5rem;
        }
        
        .abstract h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 50px;
            height: 2px;
            background: var(--accent-color);
        }

        .tldr {
            background-color: rgba(49, 130, 206, 0.05);
            padding: 1.5rem;
            border-left: 3px solid var(--accent-color);
            margin: 1.5rem 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .tldr h3 {
            color: var(--primary-color);
            margin-bottom: 0.75rem;
            font-size: 1.2rem;
            font-weight: 600;
        }

        .image-placeholder {
            width: 100%;
            height: 300px;
            background: #f1f1f1;
            display: flex;
            justify-content: center;
            align-items: center;
            border-radius: var(--border-radius);
            margin-bottom: 1.5rem;
            color: #666;
            font-size: 1.1rem;
            border: 1px solid #e2e8f0;
        }

        footer {
            background: var(--dark-bg);
            color: var(--light-text);
            text-align: center;
            padding: 2rem 0;
            margin-top: 3rem;
        }
        
        /* Highlights section */
        .highlights {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 1.5rem;
            margin: 2rem 0;
        }
        
        .highlight-item {
            flex: 1;
            min-width: 250px;
            max-width: 350px;
            background-color: white;
            padding: 1.5rem;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            text-align: left;
            border-top: 3px solid var(--accent-color);
        }
        
        .highlight-icon {
            color: var(--accent-color);
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }
        
        .highlight-item h3 {
            font-size: 1.2rem;
            margin-bottom: 0.75rem;
            color: var(--primary-color);
            font-weight: 600;
        }
        
        .highlight-item p {
            color: var(--text-color);
            font-size: 0.95rem;
        }
        
        /* Feature lists */
        .feature-list {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
            margin-top: 1.5rem;
        }
        
        .feature-item {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 0.5rem 0;
        }
        
        .feature-item i {
            color: var(--accent-color);
            font-size: 1rem;
        }
        
        /* Reference section */
        .reference-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
            margin-bottom: 2rem;
        }
        
        .reference-item {
            display: flex;
            gap: 0.75rem;
            padding: 0.75rem 0;
            border-bottom: 1px solid #e2e8f0;
        }
        
        .reference-number {
            min-width: 24px;
            color: var(--primary-color);
            font-weight: bold;
            text-align: center;
        }
        
        .reference-text {
            flex: 1;
        }
        
        .bibtex-container {
            margin-top: 1.5rem;
        }
        
        .bibtex-container h3 {
            color: var(--primary-color);
            margin-bottom: 0.75rem;
            font-size: 1.2rem;
            font-weight: 600;
        }
        
        .bibtex-code {
            background-color: #f8f9fa;
            padding: 1rem;
            border-radius: var(--border-radius);
            overflow-x: auto;
            font-family: monospace;
            font-size: 0.85rem;
            border: 1px solid #e2e8f0;
        }
        
        /* Image placeholder enhancements */
        .image-placeholder {
            flex-direction: column;
            gap: 0.75rem;
        }
        
        .image-placeholder i {
            color: var(--accent-color);
            opacity: 0.6;
        }
        
        .image-placeholder span {
            font-weight: 400;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2.2rem;
            }
            
            .subtitle {
                font-size: 1.2rem;
            }

            .authors {
                flex-direction: column;
                gap: 1rem;
                align-items: center;
            }

            .btn-container {
                flex-direction: column;
                align-items: center;
                gap: 1rem;
            }
            
            .btn-primary {
                width: 80%;
                justify-content: center;
            }

            .section {
                padding: 3rem 0;
                margin: 2rem 0;
            }

            .section-content {
                padding: 0 1.5rem;
            }
            
            .section-header h2 {
                font-size: 2rem;
            }
            
            .abstract {
                padding: 2rem;
            }
            
            .abstract h2 {
                font-size: 1.8rem;
            }
            
            .tldr {
                padding: 1.5rem;
            }
            
            .image-placeholder {
                height: 250px;
            }
            
            .video-container {
                transform: none;
                margin: 2rem auto;
            }
            
            .highlights {
                flex-direction: column;
                align-items: center;
                gap: 1.5rem;
            }
            
            .highlight-item {
                width: 100%;
                max-width: 100%;
            }
            
            .feature-item {
                padding: 0.6rem 1rem;
            }
            
            .reference-item {
                flex-direction: column;
                padding: 1rem;
            }
            
            .reference-number {
                align-self: flex-start;
            }
            
            .bibtex-code {
                padding: 1rem;
                font-size: 0.8rem;
            }
        }

        /* Landscape mode adjustments */
        @media (max-height: 500px) and (orientation: landscape) {
            header {
                padding-top: 48px; /* landscape:pt-48 */
            }

            .header-content {
                margin-top: 16px; /* landscape:mt-16 */
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .subtitle {
                font-size: 1rem;
                margin-bottom: 1rem;
            }
            
            .authors {
                gap: 1rem;
                margin-bottom: 1.5rem;
            }
            
            .btn-container {
                margin: 1rem 0;
            }
            
            .btn-primary {
                padding: 0.5rem 1rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <h2>Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation</h2>
                <div class="subtitle">NeurIPS 2025 (Spotlight)</div>
                <div class="authors">
                    <div class="author"><a href="https://abdo-eldesokey.github.io/" target="_blank">Abdelrahman Eldesokey</a></div>
                    <div class="author"><a href="https://scholar.google.com/citations?user=xbAU9sIAAAAJ&hl=en" target="_blank">Aleksandar Cvejic</a></div>
                    <div class="author"><a href="https://www.bernardghanem.com/" target="_blank">Bernard Ghanem</a></div>
                    <div class="author"><a href="https://peterwonka.net/" target="_blank">Peter Wonka</a></div>
                </div>
                <div class="btn-container">
                    <a href="https://arxiv.org/abs/PLACEHOLDER" class="btn-primary" target="_blank">
                        <i class="fas fa-file-pdf"></i> arXiv
                    </a>
                    <a href="https://github.com/abdo-eldesokey/mind-the-glitch" class="btn-primary" target="_blank">
                        <i class="fab fa-github"></i> GitHub
                    </a>
                    <a href="https://huggingface.co/PLACEHOLDER/mind-the-glitch" class="btn-primary" target="_blank">
                        <i class="fas fa-rocket"></i> Hugging Face
                    </a>
                </div>
            </div>
        </div>
    </header>

    <div class="container">
        <div class="video-container">
            <div class="video-placeholder">
                <p><i class="fas fa-film"></i> Teaser Video Coming Soon</p>
            </div>
        </div>
        
        <!-- <div class="highlights">
            <div class="highlight-item">
                <div class="highlight-icon">
                    <i class="fas fa-eye"></i>
                </div>
                <h3>Visual Correspondence</h3>
                <p>Novel approach to disentangle visual features from semantic features in diffusion models</p>
            </div>
            <div class="highlight-item">
                <div class="highlight-icon">
                    <i class="fas fa-chart-line"></i>
                </div>
                <h3>Visual Semantic Matching</h3>
                <p>New metric for quantifying inconsistencies in subject-driven generation</p>
            </div>
            <div class="highlight-item">
                <div class="highlight-icon">
                    <i class="fas fa-map-marker-alt"></i>
                </div>
                <h3>Spatial Localization</h3>
                <p>Precise identification of inconsistent regions in generated images</p>
            </div>
        </div> -->

        <div class="abstract">
            <h2>Abstract</h2>
            <p>
                We propose a novel approach for disentangling visual and semantic features from the backbones of pre-trained diffusion models, enabling <em>visual correspondence</em> in a manner analogous to the well-established <em>semantic correspondence</em>. 
                While diffusion model backbones are known to encode semantically rich features, they must also contain visual features to support their image synthesis capabilities. 
                However, isolating these visual features is challenging due to the absence of annotated datasets. 
                To address this, we introduce an automated pipeline that constructs image pairs with annotated semantic and visual correspondences based on existing subject-driven image generation datasets, and design a contrastive architecture to separate the two feature types. 
                Leveraging the disentangled representations, we propose a new metric, <em>Visual Semantic Matching (VSM)</em>, that quantifies visual inconsistencies in subject-driven image generation. 
                Empirical results show that our approach outperforms global feature-based metrics such as CLIP, DINO, and vision--language models in quantifying visual inconsistencies while also enabling spatial localization of inconsistent regions. 
                To our knowledge, this is the first method that supports both quantification and localization of inconsistencies in subject-driven generation, offering a valuable tool for advancing this task.
            </p>
            <div class="tldr">
                <h3>TL;DR</h3>
                <p>We disentangle visual from semantic features in diffusion models to detect and localize inconsistencies in subject-driven image generation, outperforming existing metrics like CLIP and DINO.</p>
            </div>
        </div>

        <section class="section" id="dataset">
            <div class="section-header">
                <h2>Dataset Generation Pipeline</h2>
            </div>
            <div class="section-content">
                <div class="image-placeholder">
                    <i class="fas fa-database fa-3x"></i>
                    <span>Dataset Generation Pipeline Image</span>
                </div>
                <p>Details about the dataset generation pipeline will be added here. Our automated pipeline constructs image pairs with annotated semantic and visual correspondences based on existing subject-driven image generation datasets.</p>
                <div class="feature-list">
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Automated annotation process</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Paired image construction</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Semantic and visual correspondence mapping</span>
                    </div>
                </div>
            </div>
        </section>

        <section class="section" id="architecture">
            <div class="section-header">
                <h2>Architecture</h2>
            </div>
            <div class="section-content">
                <div class="image-placeholder">
                    <i class="fas fa-network-wired fa-3x"></i>
                    <span>Architecture Diagram</span>
                </div>
                <p>Details about the architecture will be added here. We design a contrastive architecture to separate visual and semantic feature types from pre-trained diffusion model backbones.</p>
                <div class="feature-list">
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Contrastive learning framework</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Feature disentanglement mechanism</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Integration with diffusion model backbones</span>
                    </div>
                </div>
            </div>
        </section>

        <section class="section" id="results">
            <div class="section-header">
                <h2>Results</h2>
            </div>
            <div class="section-content">
                <div class="image-placeholder">
                    <i class="fas fa-chart-bar fa-3x"></i>
                    <span>Results Visualization</span>
                </div>
                <p>Details about the results will be added here. Our approach outperforms global feature-based metrics such as CLIP, DINO, and vision-language models in quantifying visual inconsistencies.</p>
                <div class="feature-list">
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Superior performance over CLIP and DINO</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Precise inconsistency localization</span>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-check-circle"></i>
                        <span>Quantitative and qualitative evaluation</span>
                    </div>
                </div>
            </div>
        </section>

        <section class="section" id="references">
            <div class="section-header">
                <h2>BibTeX</h2>
            </div>
            <div class="section-content">

                <div class="bibtex-container">                    
                    <pre class="bibtex-code">@inproceedings{eldesokey2025mindtheglitch,
  title={Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation},
  author={Eldesokey, Abdelrahman and Cvejic, Aleksandar and Ghanem, Bernard and Wonka, Peter},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025}
}</pre>
                </div>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 Mind-the-Glitch Research Team</p>
        </div>
    </footer>
</body>
</html>
